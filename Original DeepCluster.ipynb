{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original model from deep cluster, with clustering process every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "#These libraries help with dealing with image datasets\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "!pip install random2\n",
    "import random2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install kneed\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "!pip install kmeans-pytorch\n",
    "from kmeans_pytorch import kmeans, kmeans_predict\n",
    "\n",
    "import gc\n",
    "\n",
    "import faiss\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "Image.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_path= 'C:/Users/laura/Google Drive/WikiArt2/wikiart'\n",
    "genres = os.listdir(base_path)\n",
    "training_data = []\n",
    "\n",
    "#print(len(training_data))\n",
    "genres_f = []\n",
    "for genre in genres:\n",
    "        path = os.path.join(base_path, genre)\n",
    "        length = len(os.listdir(path))\n",
    "        if length > 1500:\n",
    "          genres_f.append(genre)\n",
    "\n",
    "for genre in genres_f:\n",
    "        path = os.path.join(base_path, genre)\n",
    "        class_num = genres_f.index(genre) #assigning each art category a classification based on it's index in the list\n",
    "        selected = random.sample(os.listdir(path), 1000) \n",
    "        for img in selected:\n",
    "            img_array = cv2.imread(os.path.join(path,img))\n",
    "            #img_array = Image.open(os.path.join(path,img))\n",
    "            if img_array is None:\n",
    "                    print('Wrong path:', path)\n",
    "            else:\n",
    "                    img_array = Image.fromarray(img_array)\n",
    "                    aug_im = transform(img_array)\n",
    "                    #batch_image = aug_im.unsqueeze(dim=0)\n",
    "                    #sobel_im = combined(aug_im)\n",
    "                    training_data.append([aug_im, class_num])\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(training_data, 'trainingdata.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_K= []\n",
    "y_K= []\n",
    "\n",
    "for features, label in training_data: \n",
    "    X_K.append(features)\n",
    "    y_K.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# piped AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y= []\n",
    "\n",
    "for features, label in training_data: \n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(training_data, batch_size=256, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First alexnet\n",
    "\n",
    "class AlexNet1(nn.Module):\n",
    "    def __init__(self, num_classes=4096):\n",
    "        super(AlexNet1, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunPCA(comb_scores):\n",
    "    mat = faiss.PCAMatrix(d_in=4096, d_out=256, eigen_power=-0.5)\n",
    "    mat.train(comb_scores)\n",
    "    x_pca = mat.apply_py(comb_scores)\n",
    "    return x_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunL2(x_pca):\n",
    "    norm = np.linalg.norm(x_pca, axis=1)\n",
    "    x_l2 = x_pca / norm[:, np.newaxis]\n",
    "    x_l2 = torch.tensor(x_l2)\n",
    "    return x_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunK_means(x_l2):\n",
    "    # set device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    # k-means\n",
    "    cluster_ids_x, cluster_centers = kmeans(\n",
    "        x_l2,\n",
    "        num_clusters= 14, \n",
    "        distance='euclidean', \n",
    "        device=device\n",
    "    )\n",
    "    return cluster_ids_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    comb_scores = []\n",
    "    for i, (images, labels) in enumerate(trainloader):  \n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(images)\n",
    "        comb_scores.append(outputs.detach().cpu().numpy())\n",
    "    comb_scores = np.concatenate(comb_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second alexnet\n",
    "\n",
    "class AlexNet2(nn.Module):\n",
    "    def __init__(self, num_classes=14):\n",
    "        super(AlexNet2, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU())\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(9216, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(4096, 4096))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4096\n",
    "batch_size = 256\n",
    "learning_rate = 0.05\n",
    "\n",
    "model1 = AlexNet1(4096).to(device)\n",
    "model2 = AlexNet2(14).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate, weight_decay = 0.00005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainloader)\n",
    "total_step = len(trainloader)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Alexnet\n",
    "    comb_scores = []\n",
    "    for i, (images, labels) in enumerate(trainloader):  \n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(images)\n",
    "        comb_scores.append(outputs.detach().cpu().numpy())\n",
    "    comb_scores = np.concatenate(comb_scores)\n",
    "\n",
    "    #PCA\n",
    "    X_PCA = RunPCA(comb_scores)\n",
    "    #L2\n",
    "    X_L2 = RunL2(X_PCA)\n",
    "    #K-means\n",
    "    CLUSTER_IDS_x  = RunK_means(X_L2)\n",
    "\n",
    "    #create new trainloader\n",
    "    trainloader2 = torch.utils.data.DataLoader([ [X[i], CLUSTER_IDS_x[i]] for i in range(len(training_data))], batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "    #Final Alexnet\n",
    "    #for epoch in range(num_epochs):\n",
    "    comb_scores2 = []\n",
    "    label = []\n",
    "    for i, (images, labels) in enumerate(trainloader2):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Foward pass\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "         # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in trainloader2:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model2(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            comb_scores2.append(predicted.detach().cpu().numpy())\n",
    "            label.append(labels)\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on the images: {} %'.format(100 * correct / total)) \n",
    "comb_scores2 = np.concatenate(comb_scores2)\n",
    "label = np.concatenate(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reducing learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_classes = 4096\n",
    "batch_size = 256\n",
    "learning_rate = 0.005\n",
    "\n",
    "model1 = AlexNet1(4096).to(device)\n",
    "model2 = AlexNet2(14).to(device)\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model2.parameters(), lr=learning_rate, weight_decay = 0.00005, momentum = 0.9)  \n",
    "\n",
    "\n",
    "# Train the model\n",
    "total_step = len(trainloader)\n",
    "total_step = len(trainloader)\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # First Alexnet\n",
    "    comb_scores = []\n",
    "    for i, (images, labels) in enumerate(trainloader):  \n",
    "        images = images.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model1(images)\n",
    "        comb_scores.append(outputs.detach().cpu().numpy())\n",
    "    comb_scores = np.concatenate(comb_scores)\n",
    "\n",
    "    #PCA\n",
    "    X_PCA = RunPCA(comb_scores)\n",
    "    #L2\n",
    "    X_L2 = RunL2(X_PCA)\n",
    "    #K-means\n",
    "    CLUSTER_IDS_x  = RunK_means(X_L2)\n",
    "\n",
    "    #create new trainloader\n",
    "    trainloader2 = torch.utils.data.DataLoader([ [X[i], CLUSTER_IDS_x[i]] for i in range(len(training_data))], batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "    #Final Alexnet\n",
    "    #for epoch in range(num_epochs):\n",
    "    comb_scores2 = []\n",
    "    label = []\n",
    "    for i, (images, labels) in enumerate(trainloader2):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Foward pass\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "         # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "            \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in trainloader2:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model2(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            comb_scores2.append(predicted.detach().cpu().numpy())\n",
    "            label.append(labels)\n",
    "            del images, labels, outputs\n",
    "    \n",
    "        print('Accuracy of the network on the images: {} %'.format(100 * correct / total)) \n",
    "comb_scores2 = np.concatenate(comb_scores2)\n",
    "label = np.concatenate(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('y.npy', 'wb') as f:\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping labels from cluster to original labels\n",
    "def get_reference_dict(clusters,data_label):\n",
    "    reference_label = {}\n",
    "    # For loop to run through each label of cluster label\n",
    "    for i in range(len(np.unique(clusters))):\n",
    "        index = np.where(clusters == i,1,0)\n",
    "        num = np.bincount(data_label[index==1])\n",
    "        if np.size(num) != 0:\n",
    "            num = num.argmax()\n",
    "            reference_label[i] = num\n",
    "        else:\n",
    "            reference_label[i] = 6\n",
    "    return reference_label\n",
    "# Mapping predictions to original labels\n",
    "def get_labels(clusters,reference_labels):\n",
    "    temp_labels = np.random.rand(len(clusters))\n",
    "    for i in range(len(clusters)):\n",
    "        temp_labels[i] = reference_labels[clusters[i]]\n",
    "    return temp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_labels = get_reference_dict(comb_scores2, npy)\n",
    "predicted_labels = get_labels(comb_scores2,reference_labels)\n",
    "print(f\"Accuracy for k = 14: \", accuracy_score(predicted_labels,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparing results to ground truth clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame([comb_scores2, y]).T\n",
    "results.columns = ['cluster', 'style']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = confusion_matrix(npy, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_numbers = []\n",
    "\n",
    "def create_labels():\n",
    "    for genre in genres_f:\n",
    "        class_num = genres_f.index(genre) #assigning each art category a classification based on it's index in the list\n",
    "        labels_numbers.append([genre, class_num])\n",
    "\n",
    "\n",
    "create_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_numbers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=False, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('\\nPredicted Style')\n",
    "ax.set_ylabel('Actual Style ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(labels_numbers, rotation = 90)\n",
    "ax.yaxis.set_ticklabels(labels_numbers, rotation = 360)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrt clustered labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cf_matrix = confusion_matrix(label, comb_scores2)\n",
    "\n",
    "ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=False, \n",
    "            fmt='.2%', cmap='Blues')\n",
    "\n",
    "ax.set_xlabel('\\nPredicted Style')\n",
    "ax.set_ylabel('Actual Style ');\n",
    "\n",
    "ax.xaxis.set_ticklabels(labels_numbers, rotation = 90)\n",
    "ax.yaxis.set_ticklabels(labels_numbers, rotation = 360)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
